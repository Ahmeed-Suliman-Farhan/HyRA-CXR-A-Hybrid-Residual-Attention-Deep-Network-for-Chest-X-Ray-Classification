{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4b563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (3475, 224, 224, 3), Labels: (3475,)\n",
      "Loaded best HPs from CSV: {'l2_weight': 5e-05, 'dropout': 0.3, 'filters_s1': 48, 'filters_s2': 96, 'filters_s3': 128, 'head_filters': 160, 'optimizer': 'rmsprop', 'lr': 0.001}\n",
      "Best holdout val_accuracy (from CSV): 0.9353\n",
      "\n",
      "===== Ablation [no_attention] FOLD 1/5 =====\n",
      "Epoch 1/100\n",
      "174/174 [==============================] - 14s 71ms/step - loss: 0.8621 - accuracy: 0.6327 - val_loss: 3.0610 - val_accuracy: 0.3165 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "174/174 [==============================] - 10s 55ms/step - loss: 0.6392 - accuracy: 0.7482 - val_loss: 1.2260 - val_accuracy: 0.4576 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "174/174 [==============================] - 10s 57ms/step - loss: 0.5669 - accuracy: 0.7835 - val_loss: 0.7135 - val_accuracy: 0.7079 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "174/174 [==============================] - 10s 58ms/step - loss: 0.5344 - accuracy: 0.7975 - val_loss: 0.5614 - val_accuracy: 0.7957 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "174/174 [==============================] - 10s 58ms/step - loss: 0.5027 - accuracy: 0.8112 - val_loss: 0.8415 - val_accuracy: 0.6950 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.4843 - accuracy: 0.8096\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "174/174 [==============================] - 10s 58ms/step - loss: 0.4840 - accuracy: 0.8097 - val_loss: 0.5907 - val_accuracy: 0.7957 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "174/174 [==============================] - 10s 59ms/step - loss: 0.4225 - accuracy: 0.8403 - val_loss: 0.4132 - val_accuracy: 0.8561 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 0.3991 - accuracy: 0.8558 - val_loss: 0.3843 - val_accuracy: 0.8475 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 0.3891 - accuracy: 0.8554 - val_loss: 0.5050 - val_accuracy: 0.8101 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 0.3732 - accuracy: 0.8676 - val_loss: 0.3569 - val_accuracy: 0.8734 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 0.3679 - accuracy: 0.8676 - val_loss: 0.4194 - val_accuracy: 0.8460 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.3412 - accuracy: 0.8790\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 0.3411 - accuracy: 0.8791 - val_loss: 0.3644 - val_accuracy: 0.8691 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 0.3060 - accuracy: 0.8939 - val_loss: 0.3226 - val_accuracy: 0.8748 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 0.3118 - accuracy: 0.8950 - val_loss: 0.6660 - val_accuracy: 0.7338 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2801 - accuracy: 0.9039\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 0.2801 - accuracy: 0.9040 - val_loss: 0.3445 - val_accuracy: 0.8691 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 0.2897 - accuracy: 0.9022 - val_loss: 0.3531 - val_accuracy: 0.8734 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9158\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 0.2672 - accuracy: 0.9162 - val_loss: 0.3256 - val_accuracy: 0.8921 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 0.2594 - accuracy: 0.9126 - val_loss: 0.3750 - val_accuracy: 0.8604 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2427 - accuracy: 0.9234\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 0.2430 - accuracy: 0.9234 - val_loss: 0.3634 - val_accuracy: 0.8633 - lr: 6.2500e-05\n",
      "Epoch 20/100\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 0.2487 - accuracy: 0.9176 - val_loss: 0.3357 - val_accuracy: 0.8863 - lr: 3.1250e-05\n",
      "Epoch 21/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2436 - accuracy: 0.9241\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 0.2441 - accuracy: 0.9241 - val_loss: 0.3309 - val_accuracy: 0.8935 - lr: 3.1250e-05\n",
      "Epoch 22/100\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 0.2429 - accuracy: 0.9209 - val_loss: 0.3206 - val_accuracy: 0.8921 - lr: 1.5625e-05\n",
      "Epoch 23/100\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 0.2356 - accuracy: 0.9227 - val_loss: 0.3333 - val_accuracy: 0.8892 - lr: 1.5625e-05\n",
      "Epoch 24/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2467 - accuracy: 0.9212\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 0.2462 - accuracy: 0.9212 - val_loss: 0.3368 - val_accuracy: 0.8906 - lr: 1.5625e-05\n",
      "Epoch 25/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 0.2524 - accuracy: 0.9162 - val_loss: 0.3360 - val_accuracy: 0.8921 - lr: 7.8125e-06\n",
      "Epoch 26/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2373 - accuracy: 0.9234\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 0.2372 - accuracy: 0.9234 - val_loss: 0.3361 - val_accuracy: 0.8906 - lr: 7.8125e-06\n",
      "Epoch 27/100\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 0.2338 - accuracy: 0.9227 - val_loss: 0.3294 - val_accuracy: 0.8935 - lr: 3.9063e-06\n",
      "Epoch 28/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2327 - accuracy: 0.9234\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 0.2343 - accuracy: 0.9227 - val_loss: 0.3345 - val_accuracy: 0.8892 - lr: 3.9063e-06\n",
      "Epoch 29/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 0.2398 - accuracy: 0.9205 - val_loss: 0.3284 - val_accuracy: 0.8921 - lr: 1.9531e-06\n",
      "Epoch 30/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2470 - accuracy: 0.9187\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "174/174 [==============================] - 11s 64ms/step - loss: 0.2465 - accuracy: 0.9191 - val_loss: 0.3291 - val_accuracy: 0.8935 - lr: 1.9531e-06\n",
      "Epoch 31/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 0.2390 - accuracy: 0.9241 - val_loss: 0.3308 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 32/100\n",
      "174/174 [==============================] - 11s 66ms/step - loss: 0.2343 - accuracy: 0.9252 - val_loss: 0.3307 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 33/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2430 - accuracy: 0.9219 - val_loss: 0.3283 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 34/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2436 - accuracy: 0.9205 - val_loss: 0.3298 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 35/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2402 - accuracy: 0.9223 - val_loss: 0.3316 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2361 - accuracy: 0.9255 - val_loss: 0.3305 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2347 - accuracy: 0.9219 - val_loss: 0.3313 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "174/174 [==============================] - 11s 66ms/step - loss: 0.2315 - accuracy: 0.9284 - val_loss: 0.3271 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2334 - accuracy: 0.9176 - val_loss: 0.3281 - val_accuracy: 0.8935 - lr: 1.0000e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2309 - accuracy: 0.9263 - val_loss: 0.3298 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 0.2364 - accuracy: 0.9194 - val_loss: 0.3350 - val_accuracy: 0.8906 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2421 - accuracy: 0.9227 - val_loss: 0.3313 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "174/174 [==============================] - 11s 66ms/step - loss: 0.2389 - accuracy: 0.9216 - val_loss: 0.3314 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2424 - accuracy: 0.9255 - val_loss: 0.3304 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2473 - accuracy: 0.9198 - val_loss: 0.3306 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2480 - accuracy: 0.9180 - val_loss: 0.3311 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2306 - accuracy: 0.9288 - val_loss: 0.3286 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2345 - accuracy: 0.9259 - val_loss: 0.3291 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2418 - accuracy: 0.9201 - val_loss: 0.3279 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2390 - accuracy: 0.9259 - val_loss: 0.3307 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2280 - accuracy: 0.9291 - val_loss: 0.3312 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2299 - accuracy: 0.9306 - val_loss: 0.3329 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2471 - accuracy: 0.9216 - val_loss: 0.3334 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2297 - accuracy: 0.9219 - val_loss: 0.3335 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2386 - accuracy: 0.9234 - val_loss: 0.3339 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2348 - accuracy: 0.9241 - val_loss: 0.3332 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2412 - accuracy: 0.9183 - val_loss: 0.3289 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2304 - accuracy: 0.9230 - val_loss: 0.3322 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2324 - accuracy: 0.9227 - val_loss: 0.3315 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2291 - accuracy: 0.9273 - val_loss: 0.3309 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 0.2420 - accuracy: 0.9212 - val_loss: 0.3311 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "[no_attention] Fold-1 Accuracy: 89.35%\n",
      "\n",
      "===== Ablation [no_attention] FOLD 2/5 =====\n",
      "Epoch 1/100\n",
      "174/174 [==============================] - 15s 73ms/step - loss: 0.8909 - accuracy: 0.6112 - val_loss: 1.4230 - val_accuracy: 0.3338 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.6480 - accuracy: 0.7507 - val_loss: 1.3022 - val_accuracy: 0.4532 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.5827 - accuracy: 0.7802 - val_loss: 0.6156 - val_accuracy: 0.7453 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 0.5366 - accuracy: 0.7975 - val_loss: 0.4322 - val_accuracy: 0.8317 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.5168 - accuracy: 0.7928 - val_loss: 0.5405 - val_accuracy: 0.7799 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.4853 - accuracy: 0.8183\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 0.4858 - accuracy: 0.8180 - val_loss: 0.5296 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 0.4086 - accuracy: 0.8532 - val_loss: 0.5108 - val_accuracy: 0.8029 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3834 - accuracy: 0.8583 - val_loss: 0.3469 - val_accuracy: 0.8619 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3887 - accuracy: 0.8525 - val_loss: 0.3606 - val_accuracy: 0.8676 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.3616 - accuracy: 0.8681\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3614 - accuracy: 0.8683 - val_loss: 1.4002 - val_accuracy: 0.6388 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.3328 - accuracy: 0.8863 - val_loss: 0.3190 - val_accuracy: 0.8806 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 0.3173 - accuracy: 0.8860 - val_loss: 0.3341 - val_accuracy: 0.8734 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.3025 - accuracy: 0.8992\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3019 - accuracy: 0.8996 - val_loss: 0.5132 - val_accuracy: 0.7626 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.2989 - accuracy: 0.8906 - val_loss: 0.3182 - val_accuracy: 0.8806 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2733 - accuracy: 0.9022 - val_loss: 0.3012 - val_accuracy: 0.9007 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 0.2825 - accuracy: 0.9018 - val_loss: 0.3100 - val_accuracy: 0.8791 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2785 - accuracy: 0.8992\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 0.2814 - accuracy: 0.8982 - val_loss: 0.3326 - val_accuracy: 0.8835 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2646 - accuracy: 0.9058 - val_loss: 0.2849 - val_accuracy: 0.9065 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 0.2583 - accuracy: 0.9151 - val_loss: 0.2816 - val_accuracy: 0.9065 - lr: 6.2500e-05\n",
      "Epoch 20/100\n",
      "174/174 [==============================] - 13s 74ms/step - loss: 0.2587 - accuracy: 0.9126 - val_loss: 0.2908 - val_accuracy: 0.8978 - lr: 6.2500e-05\n",
      "Epoch 21/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2610 - accuracy: 0.9122\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 0.2604 - accuracy: 0.9126 - val_loss: 0.3110 - val_accuracy: 0.8892 - lr: 6.2500e-05\n",
      "Epoch 22/100\n",
      "174/174 [==============================] - 14s 79ms/step - loss: 0.2492 - accuracy: 0.9097 - val_loss: 0.2775 - val_accuracy: 0.9036 - lr: 3.1250e-05\n",
      "Epoch 23/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 0.2508 - accuracy: 0.9191 - val_loss: 0.2824 - val_accuracy: 0.9050 - lr: 3.1250e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "174/174 [==============================] - 13s 73ms/step - loss: 0.2499 - accuracy: 0.9216 - val_loss: 0.2769 - val_accuracy: 0.9108 - lr: 3.1250e-05\n",
      "Epoch 25/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.2413 - accuracy: 0.9158 - val_loss: 0.2733 - val_accuracy: 0.9108 - lr: 3.1250e-05\n",
      "Epoch 26/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 0.2405 - accuracy: 0.9140 - val_loss: 0.2928 - val_accuracy: 0.9007 - lr: 3.1250e-05\n",
      "Epoch 27/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2496 - accuracy: 0.9176\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2492 - accuracy: 0.9180 - val_loss: 0.2767 - val_accuracy: 0.9079 - lr: 3.1250e-05\n",
      "Epoch 28/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2392 - accuracy: 0.9187 - val_loss: 0.2712 - val_accuracy: 0.9065 - lr: 1.5625e-05\n",
      "Epoch 29/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2385 - accuracy: 0.9230 - val_loss: 0.2733 - val_accuracy: 0.9122 - lr: 1.5625e-05\n",
      "Epoch 30/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9227\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2457 - accuracy: 0.9230 - val_loss: 0.2791 - val_accuracy: 0.9065 - lr: 1.5625e-05\n",
      "Epoch 31/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2408 - accuracy: 0.9219 - val_loss: 0.2788 - val_accuracy: 0.9094 - lr: 7.8125e-06\n",
      "Epoch 32/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2304 - accuracy: 0.9245\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2310 - accuracy: 0.9245 - val_loss: 0.2727 - val_accuracy: 0.9137 - lr: 7.8125e-06\n",
      "Epoch 33/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2326 - accuracy: 0.9237 - val_loss: 0.2786 - val_accuracy: 0.9065 - lr: 3.9063e-06\n",
      "Epoch 34/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.9220\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2377 - accuracy: 0.9223 - val_loss: 0.2763 - val_accuracy: 0.9094 - lr: 3.9063e-06\n",
      "Epoch 35/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2345 - accuracy: 0.9230 - val_loss: 0.2775 - val_accuracy: 0.9094 - lr: 1.9531e-06\n",
      "Epoch 36/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2305 - accuracy: 0.9220\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2299 - accuracy: 0.9223 - val_loss: 0.2791 - val_accuracy: 0.9079 - lr: 1.9531e-06\n",
      "Epoch 37/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2397 - accuracy: 0.9230 - val_loss: 0.2771 - val_accuracy: 0.9122 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2358 - accuracy: 0.9212 - val_loss: 0.2774 - val_accuracy: 0.9122 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2327 - accuracy: 0.9237 - val_loss: 0.2776 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2424 - accuracy: 0.9180 - val_loss: 0.2789 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2373 - accuracy: 0.9241 - val_loss: 0.2784 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2400 - accuracy: 0.9223 - val_loss: 0.2767 - val_accuracy: 0.9122 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2301 - accuracy: 0.9252 - val_loss: 0.2783 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2325 - accuracy: 0.9259 - val_loss: 0.2760 - val_accuracy: 0.9122 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2384 - accuracy: 0.9209 - val_loss: 0.2769 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2322 - accuracy: 0.9281 - val_loss: 0.2789 - val_accuracy: 0.9065 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.2331 - accuracy: 0.9273 - val_loss: 0.2785 - val_accuracy: 0.9079 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2354 - accuracy: 0.9284 - val_loss: 0.2770 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2274 - accuracy: 0.9219 - val_loss: 0.2779 - val_accuracy: 0.9079 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2428 - accuracy: 0.9180 - val_loss: 0.2779 - val_accuracy: 0.9079 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2340 - accuracy: 0.9187 - val_loss: 0.2783 - val_accuracy: 0.9079 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2350 - accuracy: 0.9230 - val_loss: 0.2782 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2447 - accuracy: 0.9158 - val_loss: 0.2771 - val_accuracy: 0.9122 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2338 - accuracy: 0.9248 - val_loss: 0.2771 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2308 - accuracy: 0.9223 - val_loss: 0.2786 - val_accuracy: 0.9050 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2335 - accuracy: 0.9201 - val_loss: 0.2769 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2401 - accuracy: 0.9227 - val_loss: 0.2776 - val_accuracy: 0.9079 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2327 - accuracy: 0.9219 - val_loss: 0.2769 - val_accuracy: 0.9122 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2358 - accuracy: 0.9281 - val_loss: 0.2779 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.2775 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2403 - accuracy: 0.9216 - val_loss: 0.2787 - val_accuracy: 0.9065 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2394 - accuracy: 0.9241 - val_loss: 0.2758 - val_accuracy: 0.9122 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2350 - accuracy: 0.9248 - val_loss: 0.2764 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
      "Epoch 64/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2337 - accuracy: 0.9223 - val_loss: 0.2760 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
      "Epoch 65/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2453 - accuracy: 0.9183 - val_loss: 0.2767 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 66/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2332 - accuracy: 0.9245 - val_loss: 0.2761 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 67/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2314 - accuracy: 0.9216 - val_loss: 0.2774 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 68/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2381 - accuracy: 0.9212 - val_loss: 0.2772 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 12s 70ms/step - loss: 0.2307 - accuracy: 0.9223 - val_loss: 0.2778 - val_accuracy: 0.9094 - lr: 1.0000e-06\n",
      "Epoch 70/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.2289 - accuracy: 0.9187 - val_loss: 0.2772 - val_accuracy: 0.9079 - lr: 1.0000e-06\n",
      "Epoch 71/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 0.2254 - accuracy: 0.9237 - val_loss: 0.2765 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
      "Epoch 72/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 0.2332 - accuracy: 0.9241 - val_loss: 0.2774 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
      "[no_attention] Fold-2 Accuracy: 91.37%\n",
      "\n",
      "===== Ablation [no_attention] FOLD 3/5 =====\n",
      "Epoch 1/100\n",
      "174/174 [==============================] - 15s 70ms/step - loss: 0.8277 - accuracy: 0.6572 - val_loss: 5.2064 - val_accuracy: 0.3165 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.6486 - accuracy: 0.7446 - val_loss: 1.8190 - val_accuracy: 0.3568 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.5898 - accuracy: 0.7777 - val_loss: 1.0791 - val_accuracy: 0.5856 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.5565 - accuracy: 0.7888 - val_loss: 0.9439 - val_accuracy: 0.7468 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.5170 - accuracy: 0.8032 - val_loss: 0.6405 - val_accuracy: 0.7986 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.4946 - accuracy: 0.8112 - val_loss: 0.5561 - val_accuracy: 0.8086 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.4548 - accuracy: 0.8309 - val_loss: 1.0345 - val_accuracy: 0.5856 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.4514 - accuracy: 0.8367\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.4515 - accuracy: 0.8367 - val_loss: 1.2072 - val_accuracy: 0.7295 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3991 - accuracy: 0.8561 - val_loss: 0.5033 - val_accuracy: 0.7957 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.3805 - accuracy: 0.8705 - val_loss: 0.5037 - val_accuracy: 0.7928 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.8689\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3780 - accuracy: 0.8687 - val_loss: 0.7714 - val_accuracy: 0.7583 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.3189 - accuracy: 0.8896 - val_loss: 0.4430 - val_accuracy: 0.8432 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3062 - accuracy: 0.8921 - val_loss: 0.3937 - val_accuracy: 0.8734 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.3047 - accuracy: 0.8924 - val_loss: 0.4954 - val_accuracy: 0.8144 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2986 - accuracy: 0.8985\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2993 - accuracy: 0.8982 - val_loss: 0.4401 - val_accuracy: 0.8460 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2766 - accuracy: 0.9004 - val_loss: 0.3961 - val_accuracy: 0.8719 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2784 - accuracy: 0.8981\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2787 - accuracy: 0.8978 - val_loss: 0.4677 - val_accuracy: 0.8388 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2583 - accuracy: 0.9183 - val_loss: 0.3720 - val_accuracy: 0.8719 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 0.2589 - accuracy: 0.9133 - val_loss: 0.4200 - val_accuracy: 0.8547 - lr: 6.2500e-05\n",
      "Epoch 20/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2525 - accuracy: 0.9144 - val_loss: 0.3593 - val_accuracy: 0.8806 - lr: 6.2500e-05\n",
      "Epoch 21/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2637 - accuracy: 0.9050 - val_loss: 0.3908 - val_accuracy: 0.8647 - lr: 6.2500e-05\n",
      "Epoch 22/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2596 - accuracy: 0.9169\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2596 - accuracy: 0.9169 - val_loss: 0.4786 - val_accuracy: 0.8245 - lr: 6.2500e-05\n",
      "Epoch 23/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2476 - accuracy: 0.9191 - val_loss: 0.4117 - val_accuracy: 0.8518 - lr: 3.1250e-05\n",
      "Epoch 24/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.9209\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2393 - accuracy: 0.9201 - val_loss: 0.4030 - val_accuracy: 0.8561 - lr: 3.1250e-05\n",
      "Epoch 25/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2452 - accuracy: 0.9191 - val_loss: 0.3939 - val_accuracy: 0.8619 - lr: 1.5625e-05\n",
      "Epoch 26/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2425 - accuracy: 0.9198\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2435 - accuracy: 0.9194 - val_loss: 0.4031 - val_accuracy: 0.8576 - lr: 1.5625e-05\n",
      "Epoch 27/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2415 - accuracy: 0.9209 - val_loss: 0.3726 - val_accuracy: 0.8662 - lr: 7.8125e-06\n",
      "Epoch 28/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9245\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2333 - accuracy: 0.9241 - val_loss: 0.3688 - val_accuracy: 0.8676 - lr: 7.8125e-06\n",
      "Epoch 29/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2314 - accuracy: 0.9266 - val_loss: 0.3877 - val_accuracy: 0.8604 - lr: 3.9063e-06\n",
      "Epoch 30/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2406 - accuracy: 0.9227\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2404 - accuracy: 0.9230 - val_loss: 0.3806 - val_accuracy: 0.8647 - lr: 3.9063e-06\n",
      "Epoch 31/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2309 - accuracy: 0.9259 - val_loss: 0.3798 - val_accuracy: 0.8662 - lr: 1.9531e-06\n",
      "Epoch 32/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.9220\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2339 - accuracy: 0.9216 - val_loss: 0.3784 - val_accuracy: 0.8691 - lr: 1.9531e-06\n",
      "Epoch 33/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.2307 - accuracy: 0.9234 - val_loss: 0.3740 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 34/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2547 - accuracy: 0.9187 - val_loss: 0.3747 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 35/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2258 - accuracy: 0.9281 - val_loss: 0.3781 - val_accuracy: 0.8662 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2304 - accuracy: 0.9245 - val_loss: 0.3767 - val_accuracy: 0.8662 - lr: 1.0000e-06\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2342 - accuracy: 0.9205 - val_loss: 0.3779 - val_accuracy: 0.8662 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2331 - accuracy: 0.9237 - val_loss: 0.3757 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2332 - accuracy: 0.9230 - val_loss: 0.3758 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2322 - accuracy: 0.9273 - val_loss: 0.3758 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2363 - accuracy: 0.9252 - val_loss: 0.3766 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2378 - accuracy: 0.9155 - val_loss: 0.3776 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2347 - accuracy: 0.9245 - val_loss: 0.3752 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2303 - accuracy: 0.9237 - val_loss: 0.3770 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2349 - accuracy: 0.9230 - val_loss: 0.3795 - val_accuracy: 0.8662 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2421 - accuracy: 0.9194 - val_loss: 0.3745 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2299 - accuracy: 0.9277 - val_loss: 0.3746 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.2417 - accuracy: 0.9227 - val_loss: 0.3767 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.2387 - accuracy: 0.9212 - val_loss: 0.3799 - val_accuracy: 0.8647 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2300 - accuracy: 0.9259 - val_loss: 0.3791 - val_accuracy: 0.8647 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2254 - accuracy: 0.9277 - val_loss: 0.3818 - val_accuracy: 0.8647 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2358 - accuracy: 0.9209 - val_loss: 0.3844 - val_accuracy: 0.8633 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2333 - accuracy: 0.9270 - val_loss: 0.3830 - val_accuracy: 0.8647 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2289 - accuracy: 0.9216 - val_loss: 0.3821 - val_accuracy: 0.8647 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2321 - accuracy: 0.9270 - val_loss: 0.3795 - val_accuracy: 0.8647 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2364 - accuracy: 0.9234 - val_loss: 0.3767 - val_accuracy: 0.8647 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2307 - accuracy: 0.9241 - val_loss: 0.3768 - val_accuracy: 0.8662 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2362 - accuracy: 0.9245 - val_loss: 0.3770 - val_accuracy: 0.8662 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2335 - accuracy: 0.9255 - val_loss: 0.3746 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2261 - accuracy: 0.9273 - val_loss: 0.3788 - val_accuracy: 0.8662 - lr: 1.0000e-06\n",
      "[no_attention] Fold-3 Accuracy: 88.06%\n",
      "\n",
      "===== Ablation [no_attention] FOLD 4/5 =====\n",
      "Epoch 1/100\n",
      "174/174 [==============================] - 15s 69ms/step - loss: 0.8404 - accuracy: 0.6191 - val_loss: 1.4320 - val_accuracy: 0.3165 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.6769 - accuracy: 0.7259 - val_loss: 0.8724 - val_accuracy: 0.6086 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.6049 - accuracy: 0.7647 - val_loss: 0.9664 - val_accuracy: 0.6230 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.5585 - accuracy: 0.7791 - val_loss: 0.4169 - val_accuracy: 0.8604 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.5339 - accuracy: 0.7971 - val_loss: 0.4759 - val_accuracy: 0.8518 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.5161 - accuracy: 0.8024\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.5167 - accuracy: 0.8022 - val_loss: 0.5095 - val_accuracy: 0.8403 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.4414 - accuracy: 0.8360 - val_loss: 0.3616 - val_accuracy: 0.8705 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.4147 - accuracy: 0.8439 - val_loss: 0.6181 - val_accuracy: 0.7496 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.4096 - accuracy: 0.8403\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.4087 - accuracy: 0.8410 - val_loss: 0.4873 - val_accuracy: 0.8115 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3562 - accuracy: 0.8723 - val_loss: 0.7348 - val_accuracy: 0.7381 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "174/174 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.8752\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3570 - accuracy: 0.8752 - val_loss: 0.4823 - val_accuracy: 0.8230 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3305 - accuracy: 0.8849 - val_loss: 0.3819 - val_accuracy: 0.8719 - lr: 1.2500e-04\n",
      "Epoch 13/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.3153 - accuracy: 0.8887\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.3151 - accuracy: 0.8888 - val_loss: 0.4820 - val_accuracy: 0.8158 - lr: 1.2500e-04\n",
      "Epoch 14/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.3166 - accuracy: 0.8885 - val_loss: 0.3480 - val_accuracy: 0.8906 - lr: 6.2500e-05\n",
      "Epoch 15/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2874 - accuracy: 0.8978 - val_loss: 0.3268 - val_accuracy: 0.8993 - lr: 6.2500e-05\n",
      "Epoch 16/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2926 - accuracy: 0.8928 - val_loss: 0.3589 - val_accuracy: 0.8791 - lr: 6.2500e-05\n",
      "Epoch 17/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2863 - accuracy: 0.8963\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2867 - accuracy: 0.8960 - val_loss: 0.4566 - val_accuracy: 0.8302 - lr: 6.2500e-05\n",
      "Epoch 18/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2916 - accuracy: 0.8964 - val_loss: 0.3289 - val_accuracy: 0.8921 - lr: 3.1250e-05\n",
      "Epoch 19/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2810 - accuracy: 0.8970\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2808 - accuracy: 0.8971 - val_loss: 0.4269 - val_accuracy: 0.8345 - lr: 3.1250e-05\n",
      "Epoch 20/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2824 - accuracy: 0.9050 - val_loss: 0.3638 - val_accuracy: 0.8691 - lr: 1.5625e-05\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/174 [============================>.] - ETA: 0s - loss: 0.2810 - accuracy: 0.8970\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2805 - accuracy: 0.8975 - val_loss: 0.4184 - val_accuracy: 0.8417 - lr: 1.5625e-05\n",
      "Epoch 22/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2776 - accuracy: 0.9040 - val_loss: 0.3697 - val_accuracy: 0.8763 - lr: 7.8125e-06\n",
      "Epoch 23/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2764 - accuracy: 0.9097\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2757 - accuracy: 0.9101 - val_loss: 0.3670 - val_accuracy: 0.8777 - lr: 7.8125e-06\n",
      "Epoch 24/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2774 - accuracy: 0.9032 - val_loss: 0.3791 - val_accuracy: 0.8647 - lr: 3.9063e-06\n",
      "Epoch 25/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.9057\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2742 - accuracy: 0.9058 - val_loss: 0.3809 - val_accuracy: 0.8604 - lr: 3.9063e-06\n",
      "Epoch 26/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2717 - accuracy: 0.9050 - val_loss: 0.3690 - val_accuracy: 0.8719 - lr: 1.9531e-06\n",
      "Epoch 27/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9057\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2705 - accuracy: 0.9061 - val_loss: 0.3754 - val_accuracy: 0.8647 - lr: 1.9531e-06\n",
      "Epoch 28/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2744 - accuracy: 0.9036 - val_loss: 0.3754 - val_accuracy: 0.8662 - lr: 1.0000e-06\n",
      "Epoch 29/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2750 - accuracy: 0.9011 - val_loss: 0.3758 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 30/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2811 - accuracy: 0.9050 - val_loss: 0.3751 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 31/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2755 - accuracy: 0.9032 - val_loss: 0.3737 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 32/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2657 - accuracy: 0.9072 - val_loss: 0.3712 - val_accuracy: 0.8705 - lr: 1.0000e-06\n",
      "Epoch 33/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2726 - accuracy: 0.9014 - val_loss: 0.3703 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 34/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2750 - accuracy: 0.9018 - val_loss: 0.3719 - val_accuracy: 0.8719 - lr: 1.0000e-06\n",
      "Epoch 35/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2800 - accuracy: 0.9004 - val_loss: 0.3700 - val_accuracy: 0.8719 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2735 - accuracy: 0.9029 - val_loss: 0.3711 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2760 - accuracy: 0.8971 - val_loss: 0.3746 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2808 - accuracy: 0.9018 - val_loss: 0.3747 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2737 - accuracy: 0.9036 - val_loss: 0.3746 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2803 - accuracy: 0.9014 - val_loss: 0.3690 - val_accuracy: 0.8763 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2774 - accuracy: 0.9022 - val_loss: 0.3765 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2702 - accuracy: 0.9058 - val_loss: 0.3733 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2781 - accuracy: 0.9029 - val_loss: 0.3759 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2680 - accuracy: 0.9054 - val_loss: 0.3762 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2705 - accuracy: 0.9043 - val_loss: 0.3778 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2847 - accuracy: 0.9014 - val_loss: 0.3725 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2772 - accuracy: 0.8996 - val_loss: 0.3771 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2816 - accuracy: 0.9058 - val_loss: 0.3764 - val_accuracy: 0.8676 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2760 - accuracy: 0.9014 - val_loss: 0.3773 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2692 - accuracy: 0.9079 - val_loss: 0.3739 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2725 - accuracy: 0.9032 - val_loss: 0.3751 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2706 - accuracy: 0.9094 - val_loss: 0.3729 - val_accuracy: 0.8705 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2790 - accuracy: 0.8978 - val_loss: 0.3790 - val_accuracy: 0.8647 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2750 - accuracy: 0.9072 - val_loss: 0.3745 - val_accuracy: 0.8719 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2627 - accuracy: 0.9090 - val_loss: 0.3765 - val_accuracy: 0.8691 - lr: 1.0000e-06\n",
      "[no_attention] Fold-4 Accuracy: 89.93%\n",
      "\n",
      "===== Ablation [no_attention] FOLD 5/5 =====\n",
      "Epoch 1/100\n",
      "174/174 [==============================] - 15s 68ms/step - loss: 0.8497 - accuracy: 0.6335 - val_loss: 4.5159 - val_accuracy: 0.3165 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.6573 - accuracy: 0.7392 - val_loss: 0.6625 - val_accuracy: 0.7525 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.5831 - accuracy: 0.7838 - val_loss: 1.0893 - val_accuracy: 0.5669 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.5533 - accuracy: 0.7906 - val_loss: 0.4655 - val_accuracy: 0.8101 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.5092 - accuracy: 0.8097 - val_loss: 0.4538 - val_accuracy: 0.8158 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.4963 - accuracy: 0.8101 - val_loss: 0.4926 - val_accuracy: 0.8129 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.4856 - accuracy: 0.8226\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.4846 - accuracy: 0.8230 - val_loss: 0.4670 - val_accuracy: 0.8216 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.4143 - accuracy: 0.8446 - val_loss: 0.4572 - val_accuracy: 0.8388 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.4016 - accuracy: 0.8478 - val_loss: 0.4307 - val_accuracy: 0.8288 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.3905 - accuracy: 0.8683 - val_loss: 0.5694 - val_accuracy: 0.8288 - lr: 5.0000e-04\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 12s 66ms/step - loss: 0.3859 - accuracy: 0.8640 - val_loss: 0.4269 - val_accuracy: 0.8331 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.3699 - accuracy: 0.8673 - val_loss: 0.4622 - val_accuracy: 0.8374 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.3701 - accuracy: 0.8721\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.3688 - accuracy: 0.8727 - val_loss: 0.4448 - val_accuracy: 0.8245 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.3236 - accuracy: 0.8892 - val_loss: 0.4055 - val_accuracy: 0.8489 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.3189 - accuracy: 0.8878 - val_loss: 0.3340 - val_accuracy: 0.8633 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.3184 - accuracy: 0.8939 - val_loss: 0.4351 - val_accuracy: 0.8331 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.3095 - accuracy: 0.8931\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.3091 - accuracy: 0.8932 - val_loss: 0.3410 - val_accuracy: 0.8734 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2857 - accuracy: 0.9047 - val_loss: 0.5820 - val_accuracy: 0.7842 - lr: 1.2500e-04\n",
      "Epoch 19/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2635 - accuracy: 0.9094 - val_loss: 0.3089 - val_accuracy: 0.9007 - lr: 1.2500e-04\n",
      "Epoch 20/100\n",
      "174/174 [==============================] - 12s 66ms/step - loss: 0.2792 - accuracy: 0.9036 - val_loss: 0.3014 - val_accuracy: 0.8878 - lr: 1.2500e-04\n",
      "Epoch 21/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2707 - accuracy: 0.9101 - val_loss: 0.3376 - val_accuracy: 0.8835 - lr: 1.2500e-04\n",
      "Epoch 22/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2720 - accuracy: 0.9064\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2719 - accuracy: 0.9061 - val_loss: 0.3338 - val_accuracy: 0.8835 - lr: 1.2500e-04\n",
      "Epoch 23/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2484 - accuracy: 0.9144 - val_loss: 0.3406 - val_accuracy: 0.8806 - lr: 6.2500e-05\n",
      "Epoch 24/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2628 - accuracy: 0.9176\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2623 - accuracy: 0.9180 - val_loss: 0.3497 - val_accuracy: 0.8748 - lr: 6.2500e-05\n",
      "Epoch 25/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2507 - accuracy: 0.9151 - val_loss: 0.2982 - val_accuracy: 0.8978 - lr: 3.1250e-05\n",
      "Epoch 26/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2426 - accuracy: 0.9183 - val_loss: 0.3224 - val_accuracy: 0.8820 - lr: 3.1250e-05\n",
      "Epoch 27/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.9133\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2474 - accuracy: 0.9126 - val_loss: 0.3526 - val_accuracy: 0.8748 - lr: 3.1250e-05\n",
      "Epoch 28/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2422 - accuracy: 0.9198 - val_loss: 0.3162 - val_accuracy: 0.8863 - lr: 1.5625e-05\n",
      "Epoch 29/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2479 - accuracy: 0.9180\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2488 - accuracy: 0.9180 - val_loss: 0.3538 - val_accuracy: 0.8633 - lr: 1.5625e-05\n",
      "Epoch 30/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2399 - accuracy: 0.9205 - val_loss: 0.3147 - val_accuracy: 0.8892 - lr: 7.8125e-06\n",
      "Epoch 31/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9205\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2429 - accuracy: 0.9198 - val_loss: 0.3176 - val_accuracy: 0.8849 - lr: 7.8125e-06\n",
      "Epoch 32/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2397 - accuracy: 0.9180 - val_loss: 0.3210 - val_accuracy: 0.8849 - lr: 3.9063e-06\n",
      "Epoch 33/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2416 - accuracy: 0.9180\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2412 - accuracy: 0.9180 - val_loss: 0.3193 - val_accuracy: 0.8835 - lr: 3.9063e-06\n",
      "Epoch 34/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2317 - accuracy: 0.9259 - val_loss: 0.3167 - val_accuracy: 0.8835 - lr: 1.9531e-06\n",
      "Epoch 35/100\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9267\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2334 - accuracy: 0.9270 - val_loss: 0.3163 - val_accuracy: 0.8835 - lr: 1.9531e-06\n",
      "Epoch 36/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2298 - accuracy: 0.9259 - val_loss: 0.3172 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2470 - accuracy: 0.9169 - val_loss: 0.3153 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2308 - accuracy: 0.9241 - val_loss: 0.3145 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2359 - accuracy: 0.9216 - val_loss: 0.3141 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2454 - accuracy: 0.9147 - val_loss: 0.3142 - val_accuracy: 0.8863 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2425 - accuracy: 0.9212 - val_loss: 0.3171 - val_accuracy: 0.8835 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2437 - accuracy: 0.9144 - val_loss: 0.3187 - val_accuracy: 0.8835 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2324 - accuracy: 0.9219 - val_loss: 0.3185 - val_accuracy: 0.8863 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2390 - accuracy: 0.9230 - val_loss: 0.3175 - val_accuracy: 0.8835 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "174/174 [==============================] - 13s 72ms/step - loss: 0.2440 - accuracy: 0.9112 - val_loss: 0.3164 - val_accuracy: 0.8835 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "174/174 [==============================] - 12s 71ms/step - loss: 0.2400 - accuracy: 0.9198 - val_loss: 0.3163 - val_accuracy: 0.8835 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "174/174 [==============================] - 12s 70ms/step - loss: 0.2411 - accuracy: 0.9173 - val_loss: 0.3164 - val_accuracy: 0.8835 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2504 - accuracy: 0.9119 - val_loss: 0.3155 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2316 - accuracy: 0.9255 - val_loss: 0.3154 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2400 - accuracy: 0.9201 - val_loss: 0.3166 - val_accuracy: 0.8835 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2341 - accuracy: 0.9201 - val_loss: 0.3156 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2358 - accuracy: 0.9237 - val_loss: 0.3167 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2427 - accuracy: 0.9216 - val_loss: 0.3198 - val_accuracy: 0.8835 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2452 - accuracy: 0.9158 - val_loss: 0.3156 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2331 - accuracy: 0.9234 - val_loss: 0.3139 - val_accuracy: 0.8878 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2416 - accuracy: 0.9277 - val_loss: 0.3136 - val_accuracy: 0.8878 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "174/174 [==============================] - 12s 69ms/step - loss: 0.2438 - accuracy: 0.9216 - val_loss: 0.3167 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "174/174 [==============================] - 12s 67ms/step - loss: 0.2302 - accuracy: 0.9263 - val_loss: 0.3144 - val_accuracy: 0.8878 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "174/174 [==============================] - 12s 68ms/step - loss: 0.2359 - accuracy: 0.9219 - val_loss: 0.3165 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
      "[no_attention] Fold-5 Accuracy: 90.07%\n",
      "\n",
      "==== ABLATION SUMMARY [no_attention] ====\n",
      "Accuracies per fold (%): ['89.35', '91.37', '88.06', '89.93', '90.07']\n",
      "Mean Accuracy: 89.76%      Std: 1.07%\n",
      "\n",
      "All ablation artifacts saved under ./outputs2/\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# HyRA-CXR Ablation (No-Attention / No-Residual)\n",
    "# Reads best HPs from outputs/kt_holdout_trials.csv\n",
    "# Saves all results under outputs2/\n",
    "# ================================\n",
    "\n",
    "import os,cv2, json, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras_tuner import HyperParameters\n",
    "\n",
    "# ---------- 0)   (        ) ----------\n",
    "SEED       = globals().get(\"SEED\", 42)\n",
    "BATCH_SIZE = globals().get(\"BATCH_SIZE\", 16)\n",
    "FOLDS      = globals().get(\"FOLDS\", 5)\n",
    "img_size   = globals().get(\"img_size\", 224)\n",
    "categories = globals().get(\"categories\", [\"Normal\", \"Lung_Opacity\", \"Viral_Pneumonia\"])\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# ======================\n",
    "#   (   )\n",
    "# ======================\n",
    "base_dir   = \"D://Lung X-Ray Image\"\n",
    "categories = [\"Normal\", \"Lung_Opacity\", \"Viral_Pneumonia\"]\n",
    "img_size   = 224\n",
    "\n",
    "data, labels = [], []\n",
    "for idx, category in enumerate(categories):\n",
    "    cat_dir = os.path.join(base_dir, category)\n",
    "    for fname in os.listdir(cat_dir):\n",
    "        fpath = os.path.join(cat_dir, fname)\n",
    "        img = cv2.imread(fpath)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        data.append(img)\n",
    "        labels.append(idx)\n",
    "\n",
    "data   = np.array(data, dtype=\"float32\") / 255.0\n",
    "labels = np.array(labels, dtype=\"int32\")\n",
    "\n",
    "print(f\"Loaded: {data.shape}, Labels: {labels.shape}\")\n",
    "\n",
    "\n",
    "#    \n",
    "assert \"data\" in globals() and \"labels\" in globals(), \"     data  labels    .\"\n",
    "\n",
    "# ---------- 1)    HPs   KerasTuner  ----------\n",
    "def load_best_hp_from_csv(csv_path=\"outputs/kt_holdout_trials.csv\"):\n",
    "    if not os.path.isfile(csv_path):\n",
    "        raise FileNotFoundError(f\"Could not find: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    #     \n",
    "    if \"val_accuracy_best\" not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'val_accuracy_best' column.\")\n",
    "    #   \n",
    "    df = df.sort_values(\"val_accuracy_best\", ascending=False).reset_index(drop=True)\n",
    "    row = df.iloc[0]\n",
    "    hp = HyperParameters()\n",
    "    hp.values = {\n",
    "        \"l2_weight\": float(row[\"hp_l2_weight\"]),\n",
    "        \"dropout\": float(row[\"hp_dropout\"]),\n",
    "        \"filters_s1\": int(row[\"hp_filters_s1\"]),\n",
    "        \"filters_s2\": int(row[\"hp_filters_s2\"]),\n",
    "        \"filters_s3\": int(row[\"hp_filters_s3\"]),\n",
    "        \"head_filters\": int(row[\"hp_head_filters\"]),\n",
    "        \"optimizer\": str(row[\"hp_optimizer\"]),\n",
    "        \"lr\": float(row[\"hp_lr\"]),\n",
    "    }\n",
    "    return hp, float(row[\"val_accuracy_best\"])\n",
    "\n",
    "best_hp, holdout_valacc = load_best_hp_from_csv(\"outputs/kt_holdout_trials.csv\")\n",
    "print(\"Loaded best HPs from CSV:\", best_hp.values)\n",
    "print(f\"Best holdout val_accuracy (from CSV): {holdout_valacc:.4f}\")\n",
    "\n",
    "# ---------- 2) Augmentation + Dataset pipeline (  make_ds   ) ----------\n",
    "if \"make_ds\" not in globals():\n",
    "    #     \n",
    "    augment = tf.keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.08),\n",
    "        layers.RandomZoom(0.10),\n",
    "        layers.RandomTranslation(0.05, 0.05),\n",
    "        layers.RandomContrast(0.10),\n",
    "    ], name=\"augment_pipeline\")\n",
    "\n",
    "    def make_ds(x, y, batch, training=False, seed=SEED):\n",
    "        x = np.ascontiguousarray(x, dtype=np.float32)\n",
    "        y = np.ascontiguousarray(y, dtype=np.float32)\n",
    "        with tf.device('/CPU:0'):\n",
    "            ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "            if training:\n",
    "                ds = ds.shuffle(buffer_size=min(2048, len(x)), seed=seed, reshuffle_each_iteration=True)\n",
    "                ds = ds.map(lambda img, lab: (augment(img, training=True), lab),\n",
    "                            num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            ds = ds.batch(batch, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "# ---------- 3)     ----------\n",
    "def build_hyra_from_hp_variant(\n",
    "    hp, \n",
    "    input_shape=(img_size, img_size, 3), \n",
    "    num_classes=len(categories),\n",
    "    use_residual=True, \n",
    "    use_attention=True\n",
    "):\n",
    "    l2w          = float(hp.get(\"l2_weight\"))\n",
    "    drop         = float(hp.get(\"dropout\"))\n",
    "    f1           = int(hp.get(\"filters_s1\"))\n",
    "    f2           = int(hp.get(\"filters_s2\"))\n",
    "    f3           = int(hp.get(\"filters_s3\"))\n",
    "    head_filters = int(hp.get(\"head_filters\"))\n",
    "    opt_name     = str(hp.get(\"optimizer\"))\n",
    "    lr_val       = float(hp.get(\"lr\"))\n",
    "\n",
    "    reg = regularizers.l2(l2w)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    def conv_block(x, filters, k=3, s=1):\n",
    "        x = layers.Conv2D(filters, k, strides=s, padding='same', kernel_regularizer=reg)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        return layers.ReLU()(x)\n",
    "\n",
    "    def residual_block(x, filters):\n",
    "        shortcut = x\n",
    "        x = conv_block(x, filters)\n",
    "        x = layers.Conv2D(filters, 3, padding='same', kernel_regularizer=reg)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        if shortcut.shape[-1] != filters:\n",
    "            shortcut = layers.Conv2D(filters, 1, padding='same', kernel_regularizer=reg)(shortcut)\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "        x = layers.Add()([shortcut, x])\n",
    "        return layers.ReLU()(x)\n",
    "\n",
    "    def attention_block(x, filters):\n",
    "        # Channel attention\n",
    "        w = layers.GlobalAveragePooling2D()(x)\n",
    "        w = layers.Dense(max(filters // 8, 4), activation='relu')(w)\n",
    "        w = layers.Dense(filters, activation='sigmoid')(w)\n",
    "        x = layers.Multiply()([x, layers.Reshape((1,1,filters))(w)])\n",
    "        # Spatial attention\n",
    "        s = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        s = layers.Conv2D(1, 7, padding='same', activation='sigmoid')(s)\n",
    "        return layers.Multiply()([x, s])\n",
    "\n",
    "    # ---- stem ----\n",
    "    x = layers.Conv2D(f1, 3, strides=2, padding='same', kernel_regularizer=reg)(inputs)  # 112x112\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # RB1 (Residual  )\n",
    "    if use_residual:\n",
    "        x = residual_block(x, f1)\n",
    "    else:\n",
    "        x = conv_block(x, f1)\n",
    "        x = layers.Conv2D(f1, 3, padding='same', kernel_regularizer=reg)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D(2)(x)   # 56x56\n",
    "\n",
    "    # RB2 + Attention-1\n",
    "    if use_residual:\n",
    "        x = residual_block(x, f2)\n",
    "    else:\n",
    "        x = conv_block(x, f2)\n",
    "        x = layers.Conv2D(f2, 3, padding='same', kernel_regularizer=reg)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "    if use_attention:\n",
    "        x = attention_block(x, f2)\n",
    "    x = layers.MaxPooling2D(2)(x)   # 28x28\n",
    "\n",
    "    # RB3 + Attention-2\n",
    "    if use_residual:\n",
    "        x = residual_block(x, f3)\n",
    "    else:\n",
    "        x = conv_block(x, f3)\n",
    "        x = layers.Conv2D(f3, 3, padding='same', kernel_regularizer=reg)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "    if use_attention:\n",
    "        x = attention_block(x, f3)\n",
    "    x = layers.MaxPooling2D(2)(x)   # 14x14\n",
    "\n",
    "    # ---- Head ----\n",
    "    x = layers.Conv2D(head_filters, 1, activation='relu')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(drop)(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=f\"HyRA_variant_res{int(use_residual)}_att{int(use_attention)}\")\n",
    "\n",
    "    # Optimizer ( )\n",
    "    if opt_name == \"adamw\":\n",
    "        try:\n",
    "            optimizer = tf.keras.optimizers.AdamW(learning_rate=lr_val)\n",
    "        except Exception:\n",
    "            optimizer = tf.keras.optimizers.experimental.AdamW(learning_rate=lr_val)\n",
    "    elif opt_name == \"rmsprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_val)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr_val)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def fresh_variant_model(best_hp, variant=\"no_attention\"):\n",
    "    if variant == \"no_attention\":\n",
    "        return build_hyra_from_hp_variant(best_hp, use_residual=True,  use_attention=False)\n",
    "    elif variant == \"no_residual\":\n",
    "        return build_hyra_from_hp_variant(best_hp, use_residual=False, use_attention=True)\n",
    "    else:\n",
    "        raise ValueError(\"variant must be 'no_attention' or 'no_residual'\")\n",
    "\n",
    "# ---------- 4)   5-Fold     outputs2 ----------\n",
    "def run_ablation_5fold(variant_name, hp, save_root=\"outputs2\"):\n",
    "    out_dir = os.path.join(save_root, f\"ablation_{variant_name}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    #    HPs \n",
    "    with open(os.path.join(out_dir, \"best_hps_used.json\"), \"w\") as f:\n",
    "        json.dump(hp.values, f, indent=2)\n",
    "\n",
    "    y_all_cat = to_categorical(labels, len(categories)).astype('float32')\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(data, labels), start=1):\n",
    "        print(f\"\\n===== Ablation [{variant_name}] FOLD {fold}/{FOLDS} =====\")\n",
    "        X_tr, X_va = data[tr_idx], data[va_idx]\n",
    "        y_tr, y_va = y_all_cat[tr_idx], y_all_cat[va_idx]\n",
    "\n",
    "        ds_train = make_ds(X_tr, y_tr, BATCH_SIZE, training=True,  seed=SEED)\n",
    "        ds_val   = make_ds(X_va, y_va, BATCH_SIZE, training=False, seed=SEED)\n",
    "\n",
    "        tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "        model = fresh_variant_model(hp, variant=variant_name)\n",
    "\n",
    "        cb_es  = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=40, restore_best_weights=True)\n",
    "        cb_rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "\n",
    "        history = model.fit(\n",
    "            ds_train,\n",
    "            epochs=globals().get(\"FT_EPOCHS\", 100),\n",
    "            validation_data=ds_val,\n",
    "            verbose=1,\n",
    "            callbacks=[cb_es, cb_rlr]\n",
    "        )\n",
    "\n",
    "        # \n",
    "        val_loss, val_acc = model.evaluate(ds_val, verbose=0)\n",
    "        print(f\"[{variant_name}] Fold-{fold} Accuracy: {val_acc*100:.2f}%\")\n",
    "        fold_scores.append(val_acc * 100)\n",
    "\n",
    "        #  history\n",
    "        pd.DataFrame(history.history).to_csv(\n",
    "            os.path.join(out_dir, f\"training_history_{variant_name}_fold{fold}.csv\"), index=False\n",
    "        )\n",
    "\n",
    "        #  \n",
    "        y_true, y_pred = [], []\n",
    "        for xb, yb in ds_val:\n",
    "            preds = model.predict(xb, verbose=0)\n",
    "            y_pred.extend(np.argmax(preds, axis=1))\n",
    "            y_true.extend(np.argmax(yb.numpy(), axis=1))\n",
    "\n",
    "        rep_df = pd.DataFrame(classification_report(y_true, y_pred, target_names=categories, output_dict=True)).transpose()\n",
    "        rep_df.to_csv(os.path.join(out_dir, f\"classification_report_{variant_name}_fold{fold}.csv\"))\n",
    "\n",
    "        # ()     CSV\n",
    "        # cm = confusion_matrix(y_true, y_pred)\n",
    "        # pd.DataFrame(cm, index=categories, columns=categories).to_csv(\n",
    "        #     os.path.join(out_dir, f\"confusion_matrix_{variant_name}_fold{fold}.csv\")\n",
    "        # )\n",
    "\n",
    "        tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "    print(f\"\\n==== ABLATION SUMMARY [{variant_name}] ====\")\n",
    "    print(\"Accuracies per fold (%):\", [f\"{s:.2f}\" for s in fold_scores])\n",
    "    print(f\"Mean Accuracy: {np.mean(fold_scores):.2f}%      Std: {np.std(fold_scores):.2f}%\")\n",
    "\n",
    "    #   \n",
    "    pd.DataFrame({\"fold\": list(range(1, FOLDS+1)), \"accuracy_percent\": fold_scores}).to_csv(\n",
    "        os.path.join(out_dir, f\"summary_{variant_name}.csv\"), index=False\n",
    "    )\n",
    "\n",
    "# ---------- 5)       outputs2 ----------\n",
    "run_ablation_5fold(\"no_attention\", best_hp)  #   Attention\n",
    "#run_ablation_5fold(\"no_residual\",  best_hp)  #   Residual\n",
    "print(\"\\nAll ablation artifacts saved under ./outputs2/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d92052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MyGPU_Inv_2025)",
   "language": "python",
   "name": "mygpu_inv_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
